# -*- coding: utf-8 -*-
"""COMP551_group80_assignment3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19yfR8UuqhnqNcC7mj2P8R8u-bf_ot8F6
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from scipy.optimize import check_grad
import matplotlib.pyplot as plt
import random
random.seed(42)

#load training set (60K images)
X_tr = np.load("kmnist-train-imgs.npz")["arr_0"]
y_tr = np.load("kmnist-train-labels.npz")["arr_0"]

#load test set (10K images)
X_te = np.load("kmnist-test-imgs.npz")["arr_0"]
y_te = np.load("kmnist-test-labels.npz")["arr_0"]

#flatten 28x28 images into 784-dimensional vectors
X_tr_flat = X_tr.reshape(X_tr.shape[0], -1)
X_te_flat = X_te.reshape(X_te.shape[0], -1)

#split training data into train and validation sets (10% val)
X_train_flat, X_val_flat, y_tr, y_val = train_test_split(
    X_tr_flat, y_tr, test_size=0.1, random_state=42, stratify=y_tr)

#standardize (fit on training only, apply to val and test)
scaler = StandardScaler()
X_tr_std = scaler.fit_transform(X_train_flat)
X_val_std = scaler.transform(X_val_flat)
X_te_std = scaler.transform(X_te_flat)

#verify proper data scaling and shaping

print("Training set shape:", X_tr_std.shape)
print("Test set shape:", X_te_std.shape)

print("Mean of training set", np.mean(X_tr_std))
print("Std of training set", np.std(X_tr_std))

"""Task 2: Implement MLP Model"""

#functions for loss, output, activation, and accuracy evaluation
def relu(x):
    return np.maximum(0, x)

def relu_derivative(x):
    return (x > 0).astype(float)

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    s = sigmoid(x)
    return s * (1 - s)

def leaky_relu(x, alpha=0.01):
    return np.where(x > 0, x, alpha * x)

def leaky_relu_derivative(x, alpha=0.01):
    return np.where(x > 0, 1, alpha)

def softmax(x):
    exps = np.exp(x - np.max(x, axis=1, keepdims=True))
    return exps / np.sum(exps, axis=1, keepdims=True)

def cross_entropy_loss(y_true, y_pred):
    n_samples = y_true.shape[0]
    correct_log_probs = -np.log(y_pred[range(n_samples), y_true])
    return np.mean(correct_log_probs)

def evaluate_acc(y_true, y_pred):
    return np.mean(y_true == y_pred)

class MLP:
    def __init__(self, input_size, hidden_layers, activation='relu', output_size=10):
        self.layer_sizes = [input_size] + hidden_layers + [output_size]
        self.num_layers = len(self.layer_sizes) - 1

        if activation == 'relu':
            self.activation = relu
            self.activation_derivative = relu_derivative
        elif activation == 'sigmoid':
            self.activation = sigmoid
            self.activation_derivative = sigmoid_derivative
        elif activation == 'leaky_relu':
            self.activation = leaky_relu
            self.activation_derivative = leaky_relu_derivative
        else:
            raise ValueError("Unsupported activation function.")

        self.weights = []
        self.biases = []

        for i in range(self.num_layers):
            w = np.random.randn(self.layer_sizes[i], self.layer_sizes[i+1]) * 0.01
            b = np.zeros((1, self.layer_sizes[i+1]))
            self.weights.append(w)
            self.biases.append(b)

    def forward(self, X):
        activations = [X]
        pre_activations = []

        A = X
        for i in range(self.num_layers - 1):
            Z = A @ self.weights[i] + self.biases[i]
            pre_activations.append(Z)
            A = self.activation(Z)
            activations.append(A)

        #output layer
        Z = A @ self.weights[-1] + self.biases[-1]
        pre_activations.append(Z)
        A = softmax(Z)
        activations.append(A)

        return activations, pre_activations

    def backward(self, activations, pre_activations, y_true):
        n = y_true.shape[0]
        grads_w = [None] * self.num_layers
        grads_b = [None] * self.num_layers

        #output layer gradient
        dZ = activations[-1]
        dZ[range(n), y_true] -= 1
        dZ /= n

        grads_w[-1] = activations[-2].T @ dZ
        grads_b[-1] = np.sum(dZ, axis=0, keepdims=True)

        #hidden layers
        for i in reversed(range(self.num_layers - 1)):
            dA = dZ @ self.weights[i+1].T
            dZ = dA * self.activation_derivative(pre_activations[i])
            grads_w[i] = activations[i].T @ dZ
            grads_b[i] = np.sum(dZ, axis=0, keepdims=True)

        return grads_w, grads_b


    def update_parameters(self, grads_w, grads_b, lr, reg_lambda, reg_type='l2'):
      for i in range(self.num_layers):
          if reg_type == 'l2':
              reg_term = reg_lambda * self.weights[i]
          elif reg_type == 'l1':
              reg_term = reg_lambda * np.sign(self.weights[i])
          else:
              reg_term = 0.0

          self.weights[i] -= lr * (grads_w[i] + reg_term)
          self.biases[i] -= lr * grads_b[i]

    def fit(self, X, y, lr=0.5, num_epochs=10, batch_size=64, reg_lambda=0.0, reg_type='l2'):
        n_samples = X.shape[0]
        train_acc_per_epoch = []

        for epoch in range(num_epochs):
            indices = np.arange(n_samples)
            np.random.shuffle(indices)
            X_shuffled = X[indices]
            y_shuffled = y[indices]

            for start in range(0, n_samples, batch_size):
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]

                activations, pre_activations = self.forward(X_batch)
                grads_w, grads_b = self.backward(activations, pre_activations, y_batch)

                self.update_parameters(grads_w, grads_b, lr, reg_lambda, reg_type)

            y_pred_train = self.predict(X)
            acc = evaluate_acc(y, y_pred_train)
            train_acc_per_epoch.append(acc)

            y_hat = self.forward(X)[0][-1]
            loss = cross_entropy_loss(y, y_hat)
            print(f"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}, Train Acc: {acc:.4f}")

        return train_acc_per_epoch


    def predict(self, X):
        probs = self.forward(X)[0][-1]
        return np.argmax(probs, axis=1)

#testing out model
mlp = MLP(input_size=784, hidden_layers=[32, 32], activation='relu', output_size=10)

mlp.fit(X_tr_std, y_tr, lr=0.5, num_epochs=5, batch_size=128)

y_pred = mlp.predict(X_te_std)
acc = evaluate_acc(y_te, y_pred)
print("Test accuracy:", acc)

#check gradient:
def full_gradient_check(model, X_sample, y_sample, epsilon=1e-5):
    """
    Performs gradient checking for **all weights in all layers** of the MLP.

    Parameters:
        model: instance of the MLP class
        X_sample: small input batch (e.g. X_tr_std[:5])
        y_sample: corresponding labels
        epsilon: small perturbation for finite differences

    Prints relative error for each layer and average total relative error.
    """
    #run forward + backward pass once to get backprop gradients
    activations, pre_activations = model.forward(X_sample)
    grads_w, grads_b = model.backward(activations, pre_activations, y_sample)

    total_relative_error = 0
    total_weights = 0

    for layer in range(model.num_layers):
        W = model.weights[layer]
        grad_backprop = grads_w[layer]

        #iterate over each element in W
        for i in range(W.shape[0]):
            for j in range(W.shape[1]):
                original_value = W[i, j]

                #numerical gradient
                W[i, j] = original_value + epsilon
                loss_plus = cross_entropy_loss(y_sample, model.forward(X_sample)[0][-1])

                W[i, j] = original_value - epsilon
                loss_minus = cross_entropy_loss(y_sample, model.forward(X_sample)[0][-1])

                W[i, j] = original_value  # Reset

                grad_num = (loss_plus - loss_minus) / (2 * epsilon)
                grad_bp = grad_backprop[i, j]

                #relative error
                rel_error = abs(grad_bp - grad_num) / (abs(grad_bp) + abs(grad_num) + 1e-8)
                total_relative_error += rel_error
                total_weights += 1

                if rel_error > 1e-5:
                    print(f"W[{layer}][{i},{j}] - Rel error: {rel_error:.2e}")

    avg_rel_error = total_relative_error / total_weights
    print(f"\nAverage relative error across all weights: {avg_rel_error:.2e}")

#gradient check
X_sample = X_tr_std[:3]
y_sample = y_tr[:3]

test_model = MLP(input_size=784, hidden_layers=[3], activation='relu', output_size=10)

full_gradient_check(test_model, X_sample, y_sample)

"""Hyperparameter Selection

"""

#find optimal learning rate

learning_rates = [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9]
val_accuracies = []
num_epochs = 5

for lr in learning_rates:
    print(f"\n Training with learning rate: {lr}")
    model = MLP(input_size=784, hidden_layers=[32, 32], activation='relu', output_size=10)
    model.fit(X_val_std, y_val, lr=lr, num_epochs=num_epochs, batch_size=128)
    y_val_pred = model.predict(X_val_std)
    val_acc = evaluate_acc(y_val, y_val_pred)
    val_accuracies.append(val_acc)
    print(f"Validation accuracy for lr={lr}: {val_acc:.4f}")

plt.plot(learning_rates, val_accuracies, marker='o')
plt.xscale('log')
plt.xlabel('Learning Rate')
plt.ylabel('Validation Accuracy')
plt.title('Learning Rate vs Validation Accuracy')
plt.grid(True)
plt.show()

"""Experiments"""

#EXPERIMENT 1 creating three different models
hidden_sizes = [32, 64, 128, 256]

#no hidden layer
no_hidden_MLP = MLP(input_size=784, hidden_layers=[], activation='relu', output_size=10)
no_hidden_MLP.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128)
y_pred_nhMLP = no_hidden_MLP.predict(X_val_std)
best_acc_no = evaluate_acc(y_val, y_pred_nhMLP)
print(f"No Hidden Layer MLP - Validation Accuracy: {best_acc_no:.4f}")

#single hidden layer
best_acc_single = -1
best_size_single = None

for size in hidden_sizes:
    model = MLP(input_size=784, hidden_layers=[size], activation='relu', output_size=10)
    model.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128)
    y_pred = model.predict(X_val_std)
    acc = evaluate_acc(y_val, y_pred)
    print(f"Single Hidden Layer ({size}) - Validation Accuracy: {acc:.4f}")

    if acc > best_acc_single:
        best_acc_single = acc
        best_size_single = size

print(f"\n Best Single Hidden Layer Size: {best_size_single} with Accuracy: {best_acc_single:.4f}")

#double hidden layer
best_acc_double = -1
best_size_double = None

for size in hidden_sizes:
    model = MLP(input_size=784, hidden_layers=[size, size], activation='relu', output_size=10)
    model.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128)
    y_pred = model.predict(X_val_std)
    acc = evaluate_acc(y_val, y_pred)
    print(f"Double Hidden Layers ({size}, {size}) - Validation Accuracy: {acc:.4f}")

    if acc > best_acc_double:
        best_acc_double = acc
        best_size_double = size

print(f"\n Best Double Hidden Layer Size: ({best_size_double}, {best_size_double}) with Accuracy: {best_acc_double:.4f}")

def train_and_track_accuracy(model, X_train, y_train, X_test, y_test, lr, num_epochs, batch_size):
    train_acc_list = []
    test_acc_list = []

    for epoch in range(num_epochs):
        #train for 1 epoch at a time
        model.fit(X_train, y_train, lr=lr, num_epochs=1, batch_size=batch_size)

        #training accuracy
        y_train_pred = model.predict(X_train)
        train_acc = evaluate_acc(y_train, y_train_pred)
        train_acc_list.append(train_acc)

        #test accuracy
        y_test_pred = model.predict(X_test)
        test_acc = evaluate_acc(y_test, y_test_pred)
        test_acc_list.append(test_acc)

    return train_acc_list, test_acc_list

#best hidden sizes from validation
best_size_single = 256
best_size_double = 256

no_hidden_final = MLP(input_size=784, hidden_layers=[], activation='relu', output_size=10)
no_hidden_final.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128)
y_pred_no = no_hidden_final.predict(X_te_std)
acc_no = evaluate_acc(y_te, y_pred_no)
print(f"No Hidden Layer Test Accuracy: {acc_no:.4f}")

single_hidden_final = MLP(input_size=784, hidden_layers=[best_size_single], activation='relu', output_size=10)
single_hidden_final.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128)
y_pred_single = single_hidden_final.predict(X_te_std)
acc_single = evaluate_acc(y_te, y_pred_single)
print(f"Single Hidden Layer [{best_size_single}] Test Accuracy: {acc_single:.4f}")

double_hidden_final = MLP(input_size=784, hidden_layers=[best_size_double, best_size_double], activation='relu', output_size=10)
double_hidden_final.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128)
y_pred_double = double_hidden_final.predict(X_te_std)
acc_double = evaluate_acc(y_te, y_pred_double)
print(f"Double Hidden Layer [{best_size_double}, {best_size_double}] Test Accuracy: {acc_double:.4f}")

#no hidden layer
no_hidden_final = MLP(input_size=784, hidden_layers=[], activation='relu', output_size=10)
no_train_acc, no_test_acc = train_and_track_accuracy(
    no_hidden_final, X_tr_std, y_tr, X_te_std, y_te, lr=0.5, num_epochs=10, batch_size=128
)

#single hidden layer
single_hidden_final = MLP(input_size=784, hidden_layers=[best_size_single], activation='relu', output_size=10)
single_train_acc, single_test_acc = train_and_track_accuracy(
    single_hidden_final, X_tr_std, y_tr, X_te_std, y_te, lr=0.5, num_epochs=10, batch_size=128
)

#double hidden layer
double_hidden_final = MLP(input_size=784, hidden_layers=[best_size_double, best_size_double], activation='relu', output_size=10)
double_train_acc, double_test_acc = train_and_track_accuracy(
    double_hidden_final, X_tr_std, y_tr, X_te_std, y_te, lr=0.5, num_epochs=10, batch_size=128
)

def plot_acc(train_acc, test_acc, label, color):
    plt.plot(train_acc, label=f'{label} - Train', linestyle='-', color=color)
    plt.plot(test_acc, label=f'{label} - Test', linestyle='--', color=color)

plt.figure(figsize=(10, 6))
plot_acc(no_train_acc, no_test_acc, 'No Hidden', 'blue')
plot_acc(single_train_acc, single_test_acc, 'Single Hidden', 'green')
plot_acc(double_train_acc, double_test_acc, 'Double Hidden', 'red')

plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Training and Testing Accuracy per Epoch")
plt.legend()
plt.grid(True)
plt.show()

#best hidden sizes experiment
best_size_single = 128
best_size_double = 128

no_hidden_final = MLP(input_size=784, hidden_layers=[], activation='relu', output_size=10)
no_hidden_final.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128)
y_pred_no = no_hidden_final.predict(X_te_std)
acc_no = evaluate_acc(y_te, y_pred_no)
print(f"No Hidden Layer Test Accuracy: {acc_no:.4f}")

single_hidden_final = MLP(input_size=784, hidden_layers=[best_size_single], activation='relu', output_size=10)
single_hidden_final.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128)
y_pred_single = single_hidden_final.predict(X_te_std)
acc_single = evaluate_acc(y_te, y_pred_single)
print(f"Single Hidden Layer [{best_size_single}] Test Accuracy: {acc_single:.4f}")

double_hidden_final = MLP(input_size=784, hidden_layers=[best_size_double, best_size_double], activation='relu', output_size=10)
double_hidden_final.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128)
y_pred_double = double_hidden_final.predict(X_te_std)
acc_double = evaluate_acc(y_te, y_pred_double)
print(f"Double Hidden Layer [{best_size_double}, {best_size_double}] Test Accuracy: {acc_double:.4f}")

#EXPERIMENT 2 - Using 256 as hidden layer size because most accurate
double_hidden_sigmoid_MLP = MLP(input_size=784, hidden_layers=[256, 256], activation='sigmoid', output_size=10)
double_hidden_sigmoid_MLP.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128)

y_pred_dhsigMLP = double_hidden_sigmoid_MLP.predict(X_te_std)
acc = evaluate_acc(y_te, y_pred_dhsigMLP)
print("Test accuracy double hidden sigmoid MLP:", acc)

double_hidden_leakyReLU_MLP = MLP(input_size=784, hidden_layers=[256, 256], activation='leaky_relu', output_size=10)
double_hidden_leakyReLU_MLP.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128)

y_pred_dhleakyMLP = double_hidden_leakyReLU_MLP.predict(X_te_std)
acc = evaluate_acc(y_te, y_pred_dhleakyMLP)
print("Test accuracy double hidden leaky ReLU MLP:", acc)

double_hidden_relu_MLP = MLP(input_size=784, hidden_layers=[256, 256], activation='relu', output_size=10)
double_hidden_relu_MLP.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128)

y_pred_dhreluMLP = double_hidden_relu_MLP.predict(X_te_std)
acc_relu = evaluate_acc(y_te, y_pred_dhreluMLP)
print("Test accuracy double hidden ReLU MLP:", acc_relu)

#for plotting
activations = ['Sigmoid', 'Leaky ReLU', 'ReLU']
accuracies = [
    evaluate_acc(y_te, y_pred_dhsigMLP),
    evaluate_acc(y_te, y_pred_dhleakyMLP),
    acc_relu
]

plt.bar(activations, accuracies, color=['skyblue', 'lightgreen', 'purple'])
plt.title("Test Accuracy of Double Hidden MLP with Different Activations")
plt.ylabel("Test Accuracy")
plt.ylim(0.5, 1)  # Accuracy is between 0 and 1
plt.yticks(np.arange(0.5, 1.01, 0.05))
plt.grid(axis='y')
plt.show()

#EXPERIMENT 3 training model with L2 regularization, takes ~7 minutes to run

#lambda values to test
lambda_values = [0.0, 1e-5, 1e-4, 1e-3, 0.01, 0.03, 0.05, 0.1]

val_accs = {}

for lam in lambda_values:
    model_l2 = MLP(input_size=784, hidden_layers=[128, 128], activation='relu', output_size=10)
    model_l2.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128, reg_lambda=lam)

    y_pred_val = model_l2.predict(X_val_std)
    acc = evaluate_acc(y_val, y_pred_val)

    val_accs[lam] = acc
    print(f"Validation accuracy with lambda = {lam}: {acc:.4f}")


best_lambda = max(val_accs, key=val_accs.get)
print(f"\nBest lambda from validation: {best_lambda}")

#final model on training set
final_model = MLP(input_size=784, hidden_layers=[256, 256], activation='relu', output_size=10)
final_model.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128, reg_lambda=best_lambda)

#evaluate on test set
y_pred_test = final_model.predict(X_te_std)
final_test_acc = evaluate_acc(y_te, y_pred_test)
print(f"Final Test Accuracy with L2 (lambda={best_lambda}): {final_test_acc:.4f}")

lambdas = list(val_accs.keys())
accuracies = list(val_accs.values())

plt.plot(lambdas, accuracies, marker='o')
plt.xscale('log')
plt.xlabel('Lambda (L2 Regularization Strength)')
plt.ylabel('Validation Accuracy')
plt.title('Effect of L2 Regularization on Validation Accuracy')
plt.grid(True)
plt.show()

#CREATIVE EXPERIMENT: L1 REGULARIZATION

#lambda values to test
lambda_values = [0.0, 1e-5, 1e-4, 1e-3, 0.01, 0.03, 0.05, 0.1]

val_accs_l1 = {}

for lam in lambda_values:
    model_l1 = MLP(input_size=784, hidden_layers=[128, 128], activation='relu', output_size=10)
    model_l1.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128, reg_lambda=lam, reg_type='l1')

    y_pred_val = model_l1.predict(X_val_std)
    acc = evaluate_acc(y_val, y_pred_val)

    val_accs_l1[lam] = acc
    print(f"Validation accuracy with L1 lambda = {lam}: {acc:.4f}")

best_lambda_l1 = max(val_accs_l1, key=val_accs_l1.get)
print(f"\nBest L1 lambda from validation: {best_lambda_l1}")

#final model on training set with best L1 lambda
final_model_l1 = MLP(input_size=784, hidden_layers=[256, 256], activation='relu', output_size=10)
final_model_l1.fit(X_tr_std, y_tr, lr=0.5, num_epochs=10, batch_size=128, reg_lambda=best_lambda_l1, reg_type='l1')


y_pred_test_l1 = final_model_l1.predict(X_te_std)
final_test_acc_l1 = evaluate_acc(y_te, y_pred_test_l1)
print(f"Final Test Accuracy with L1 (lambda={best_lambda_l1}): {final_test_acc_l1:.4f}")

#plot
lambdas = list(val_accs_l1.keys())
accuracies = list(val_accs_l1.values())

plt.plot(lambdas, accuracies, marker='o')
plt.xscale('log')
plt.xlabel('Lambda (L1 Regularization Strength)')
plt.ylabel('Validation Accuracy')
plt.title('Effect of L1 Regularization on Validation Accuracy')
plt.grid(True)
plt.show()

#EXPERIMENT 4 imports
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

def plot_history(history, units):
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title(f"Training vs Validation Accuracy ({units} units)")
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)
    plt.show()

#EXPERIMENT 4 data reshaping
X_tr = np.load("kmnist-train-imgs.npz")["arr_0"]
y_tr = np.load("kmnist-train-labels.npz")["arr_0"]

X_tr = X_tr / 255.0
X_te = X_te / 255.0

X_tr = X_tr.reshape(-1, 28, 28, 1)
X_te = X_te.reshape(-1, 28, 28, 1)

#one-hot encode labels
y_tr_cat = to_categorical(y_tr, num_classes=10)
y_te_cat = to_categorical(y_te, num_classes=10)

#validation set
X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr_cat, test_size=0.1, random_state=42)

#EXPERIMENT 4 model definition

def build_cnn(hidden_units):
    model = models.Sequential()

    #Conv layers with ReLU
    model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))
    model.add(layers.MaxPooling2D((2,2)))

    model.add(layers.Conv2D(64, (3,3), activation='relu'))
    model.add(layers.MaxPooling2D((2,2)))

    model.add(layers.Conv2D(128, (3,3), activation='relu'))

    model.add(layers.Flatten())

    #Fully connected layers with ReLU
    model.add(layers.Dense(hidden_units, activation='relu'))
    model.add(layers.Dense(10, activation='softmax'))  # Output layer

    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

#EXPERIMENT 4 hyperparameter tuning
fc_units_list = [32, 64, 128, 256]
results = {}

for units in fc_units_list:
    print(f"\n Training model with {units} hidden units")
    model = build_cnn(hidden_units=units)
    history = model.fit(X_train, y_train, epochs=5, batch_size=64,
                        validation_data=(X_val, y_val), verbose=1)

    plot_history(history, units)

    val_acc = history.history['val_accuracy'][-1]
    results[units] = val_acc

#display results
print("\n Validation Accuracies:")
for units, acc in results.items():
    print(f"{units} hidden units: {acc:.4f}")

#best
best_units = max(results, key=results.get)
print(f"\n Best hidden units: {best_units}")

#EXPERIEMENT 4 evaluate model with best hyperparameters
best_model = build_cnn(hidden_units=best_units)
best_model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)
test_loss, test_acc = best_model.evaluate(X_te, y_te_cat)
print(f"\n Test accuracy: {test_acc:.4f}")